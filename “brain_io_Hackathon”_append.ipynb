{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "\n",
        "import scipy.io\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from mne.decoding import CSP"
      ],
      "metadata": {
        "id": "JlHos5Xlv1I-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5c44f37-8bf1-42ad-a24d-7632939d6dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mne\n",
            "  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.9/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.9/dist-packages (from mne) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mne) (2.1.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (4.39.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mne) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.15)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat = scipy.io.loadmat('Walk.mat')\n",
        "mat\n",
        "ecog_data = mat['y']"
      ],
      "metadata": {
        "id": "aL-8hdr60h3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paradigmInfo = scipy.io.loadmat('Walk_paradigmInfo.mat')"
      ],
      "metadata": {
        "id": "UV95pnWc0PL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Walk_settings.txt') as f:\n",
        "  settings = f.read()\n",
        "  print(settings)"
      ],
      "metadata": {
        "id": "6gjUfZY40ZGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6885519f-2de4-4796-ded4-48dd7a3ee9fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fs: 1200/128\n",
            "\n",
            "CH1: time\n",
            "CH2-161: ECoG 1-160\n",
            "CH162: DI (Photodiode Feedback)\n",
            "CH163: StimCode\n",
            "CH164: GroupId\n",
            "\n",
            "no reference\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Walk_paradigm.xml') as f:\n",
        "  paradigminfo = f.read()\n",
        "  print(paradigminfo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIyPCDWl1d6Y",
        "outputId": "2c449e57-530e-4883-8045-41222d222a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
            "<Data  xmlns=\"xsd\"\n",
            "           xmlns:ns=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
            "           ns:schemaLocation=\"xsd C:\\_SVN\\ECoGmeToo\\trunk\\sources\\ParadigmTools\\src\\main\\Paradigm\\ParadigmSchema.xsd\">\n",
            "\n",
            "  <Paradigm BaseFolder=\"media/\">\n",
            "    <Task ns:type=\"SingleTask\" ID=\"ST_PreParadigm\" DurationSeconds=\"10\">\n",
            "      <Stimulus ns:type=\"TextStimulus\" Caption=\"+\"/>\n",
            "    </Task>\n",
            "    <Task ns:type=\"SingleTask\" ID=\"ST_Video\" DurationSeconds=\"252\" Group=\"1\">\n",
            "      <Stimulus ns:type=\"VideoStimulus\" FileName=\"walk.mp4\"/>\n",
            "    </Task>\n",
            "    <Task ns:type=\"SingleTask\" ID=\"ST_PostParadigm\" DurationSeconds=\"5\">\n",
            "      <Stimulus ns:type=\"TextStimulus\" Caption=\"Thank You!\"/>\n",
            "    </Task>\n",
            "  </Paradigm>\n",
            "\n",
            "</Data>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data exploration"
      ],
      "metadata": {
        "id": "d9zZwN1RMkU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels ={\n",
        "    'digit': ['0:10-0:17', '0:36-0:41', '3:51-3:54', '3:59-4:02'], \n",
        "    'kanji': ['0:27-0:36', '3:42-3:46', '3:54-3:56', '4:02-4:04'],\n",
        "    'face': ['0:47-0:53', '1:53-2:00', '2:31-2:37', '2:46-2:52', '2:59-3:04', '4:05-4:12'],\n",
        "    'hira': ['0:56-1:02'],\n",
        "    \"object\": ['1:25-1:32', '1:53-1:55', '1:59-2:03', '2:10-2:20', '3:12-3:30', '3:48-4:04'],\n",
        "    \"line\": ['1:35-1:40', '3:49-3:51'],\n",
        "    \"body\": ['1:48-2:03', '2:26-2:36', '2:53-3:03', '3:32-3:45', '3:56-3:59']\n",
        "}"
      ],
      "metadata": {
        "id": "xg7e8xdpMmHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_channels = np.zeros((7, 322049))\n",
        "label_channels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkwBE5VKMnCL",
        "outputId": "a95ff3c0-7e38-4e76-b123-31c7b0fdaf79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7, 322049)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for key in labels:\n",
        "\n",
        "  key_to_idx = {\n",
        "      'body': 0, \n",
        "      'face': 1,\n",
        "      'digit': 2,\n",
        "      'hira': 3,\n",
        "      'kanji': 4,\n",
        "      'line': 5,\n",
        "      'object': 6,     \n",
        "  }\n",
        "\n",
        "  for span in labels[key]:\n",
        "    start_time, end_time = span.split('-')\n",
        "    min, sec = start_time.split(':')\n",
        "    start_frame = (int(min) * 60 + int(sec) * 1) * 1200\n",
        "    min, sec = end_time.split(':')\n",
        "    end_frame = (int(min) * 60 + int(sec) * 1) * 1200\n",
        "    print(key, start_frame, end_frame)\n",
        "    label_channels[key_to_idx[key]][start_frame:end_frame] = 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaBH2fsEMm2J",
        "outputId": "1441bc45-9edd-4f4c-eddf-b5b08d71c0ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digit 12000 20400\n",
            "digit 43200 49200\n",
            "digit 277200 280800\n",
            "digit 286800 290400\n",
            "kanji 32400 43200\n",
            "kanji 266400 271200\n",
            "kanji 280800 283200\n",
            "kanji 290400 292800\n",
            "face 56400 63600\n",
            "face 135600 144000\n",
            "face 181200 188400\n",
            "face 199200 206400\n",
            "face 214800 220800\n",
            "face 294000 302400\n",
            "hira 67200 74400\n",
            "object 102000 110400\n",
            "object 135600 138000\n",
            "object 142800 147600\n",
            "object 156000 168000\n",
            "object 230400 252000\n",
            "object 273600 292800\n",
            "line 114000 120000\n",
            "line 274800 277200\n",
            "body 129600 147600\n",
            "body 175200 187200\n",
            "body 207600 219600\n",
            "body 254400 270000\n",
            "body 283200 286800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing steps\n"
      ],
      "metadata": {
        "id": "aXWcSS8q11SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Isolate ECoG data corresponding to video"
      ],
      "metadata": {
        "id": "FN0-ois9349Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the indices of the columns where the last row is 1\n",
        "video_indices = np.where(ecog_data[-1] == 1)[0]\n",
        "video_data = ecog_data[:, video_indices]\n",
        "stim_1_data = ecog_data[:, np.where(ecog_data[-2] == 1)[0]]\n",
        "stim_2_data = ecog_data[:, np.where(ecog_data[-2] == 2)[0]]\n",
        "stim_3_data = ecog_data[:, np.where(ecog_data[-2] == 3)[0]]"
      ],
      "metadata": {
        "id": "PT4GGiMu1fd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = video_data[1:161]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg6iOwX19Iu3",
        "outputId": "57cf7da1-48f5-4610-b8ff-e7f49387c423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -9394.972  ,  -9312.645  ,  -9271.435  , ...,  -9453.155  ,\n",
              "         -9442.572  ,  -9445.171  ],\n",
              "       [ -8803.406  ,  -8740.629  ,  -8708.926  , ...,  -3479.4329 ,\n",
              "         -3467.3655 ,  -3467.9377 ],\n",
              "       [-46186.574  , -46110.555  , -46068.73   , ..., -42955.52   ,\n",
              "        -42940.566  , -42941.434  ],\n",
              "       ...,\n",
              "       [  1472.1324 ,   1551.2363 ,   1598.5604 , ...,   -693.6732 ,\n",
              "          -682.31055,   -686.2936 ],\n",
              "       [-37829.125  , -37747.676  , -37700.152  , ..., -38397.707  ,\n",
              "        -38385.68   , -38391.67   ],\n",
              "       [-64281.17   , -64203.22   , -64156.484  , ..., -64058.324  ,\n",
              "        -64047.703  , -64049.297  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Implement high pass filter - not needed since no visual inspection done? \n",
        "fs = 1200\n",
        "HP_freq = "
      ],
      "metadata": {
        "id": "nZaw_YcI-Zbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement bandpass filter to isolate broadband gamma activity \n",
        "fs = 1200\n",
        "\n",
        "#110-140\n",
        "low_pass_freq = 110\n",
        "high_pass_freq = 140\n",
        "filter_order = 4\n",
        "nyq_freq = 0.5*fs\n",
        "\n",
        "b, a = signal.butter(filter_order, [low_pass_freq / nyq_freq, high_pass_freq / nyq_freq], btype='bandpass')\n",
        "\n",
        "x_filt = signal.filtfilt(b,a,x, axis=1)\n",
        "\n",
        "#If time permits, could also look at lower frequency gamma band (30-100 Hz) but will need to use notch filter to remove power noise (50 or 60 Hz depending on where data was collected)"
      ],
      "metadata": {
        "id": "mw9CzSlKARGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data to apply Common Spatial Patterns filter\n",
        "\n",
        "#Extract each trial (exposure to one stimulus) from 100ms to 600ms after exposure and stack in an array + create another vector for the corresponding labels\n"
      ],
      "metadata": {
        "id": "W2ddvZrPEdjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get CLF and apply to data"
      ],
      "metadata": {
        "id": "YOVluea7mpYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepped_data: Data needs to be in (trial, channel, sample) format where each trial has the same number of samples \n",
        "# Labels need to be in a separate vector of length (trial) with a number corresponding to the type of stimulus (face, letters, digits, etc)\n",
        "\n",
        "num_classes = len(np.unique(labels))\n",
        "\n",
        "csp_list = []\n",
        "lda_list = [] \n",
        "\n",
        "for class_number in range(num_classes):\n",
        "  labels_binary = np.zeros(labels.shape)\n",
        "  labels_binary[labels == class_number] = 1\n",
        "  labels_binary[labels != class_number] = -1\n",
        "\n",
        "  #Fit pipeline to data\n",
        "  csp = CSP(n_components=4, reg=None, log=None, norm_trace=False)\n",
        "  lda = LDA()\n",
        "  clf = Pipeline([('CSP', csp), ('LDA', lda)])\n",
        "  clf.fit(prepped_data, labels_binary)\n",
        "\n",
        "  #Save for later\n",
        "  csp_list.append(csp)\n",
        "  lda_list.append(lda)\n"
      ],
      "metadata": {
        "id": "s2etkBDRgU2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csp_filtered_data_list = []\n",
        "\n",
        "for csp in csp_list:\n",
        "  csp_data = csp.transform(prepped_data)\n",
        "  csp_filtered_data_list.append(csp_data)\n",
        "\n",
        "#combine all data\n",
        "final_data = np.concatenate(csp_filtered_data_list, axis=-1)\n"
      ],
      "metadata": {
        "id": "NAQ1BSgtmsVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the labels need to be generned with the filter_data\n",
        "# count variances\n",
        "variances = []\n",
        "for csp_data in final_data:\n",
        "  variances.append(np.var(window_data))\n",
        "variances = np.array(variances)\n",
        "\n",
        "# filter with the variances\n",
        "new_data, new_label = [],[]\n",
        "for dat,label in zip(final_data, final_label):\n",
        "  if np.var(window_data)) > np.percentile(variances, 25):\n",
        "    new_data.append(dat)\n",
        "    new_label.append(label)\n",
        "final_data = np.array(new_data)\n",
        "final_label = np.array(new_label)\n",
        "\n"
      ],
      "metadata": {
        "id": "ffG2knp-O6eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model and find biomarkers\n",
        "\n",
        "cv = ShuffleSplit(10, test_size=0.2)\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "scores = cross_val_score(clf, fina_data, final_labels, cv=cv)\n",
        "\n",
        "\n",
        "from sklearn import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import shap\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
        "scores = cross_val_score(clf, final_data, final_labels, cv=cv)\n",
        "clf.fit(epochs_data_train, labels)\n",
        "importances = clf.feature_importances_\n",
        "\n",
        "\n",
        "clf = XGBClassifier(n_setimators=100)\n",
        "scores = cross_val_score(clf, final_data, final_labels, cv=cv)\n",
        "clf.fit(epochs_data_train, labels)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(final_data)\n",
        "shap.force_plot(explainer.expected_value, shap_values, final_data)\n",
        "\n",
        "shap_interaction_values = explainer.shap_interaction_values(final_data)\n",
        "shap.summary_plot(shap_interaction_values, final_data)"
      ],
      "metadata": {
        "id": "g4rdvJ-onliq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IGNORE THIS CELL\n",
        "\n",
        "#CSP attempt 1 - going to try again using MNE library \n",
        "\n",
        "def get_csp(data, labels, n_components): \n",
        "  num_classes = len(np.unique(labels))\n",
        "  #Get class means\n",
        "  class_means = [np.mean(data[labels == class_num], axis=0) for class_num in np.unique(labels)]\n",
        "\n",
        "  #Compute spatial covariance matrices for each class\n",
        "  covs = [np.cov(data[labels == class_num], rowvar=False) for class_num in np.unique(labels)]\n",
        "\n",
        "  #Get eigenval problem for cov\n",
        "  _, V = eigh(covs[0], covs[0] + covs[1] + covs[2])\n",
        "  V = V[:,::-1]     #Sort by descending eigenvalue\n",
        "\n",
        "  filters = []\n",
        "  for i in range(num_classes):\n",
        "      class_i = i\n",
        "      other_classes = np.setdiff1d(np.arange(num_classes), class_i)\n",
        "      class_data = data[labels == class_i]\n",
        "      other_class_data = data[np.isin(labels, other_classes)]\n",
        "      cov_i = np.cov(class_data.reshape(-1, class_data.shape[-1]), rowvar=False)\n",
        "      cov_other_classes = np.cov(other_class_data.reshape(-1, other_class_data.shape[-1]), rowvar=False)\n",
        "      _, V = eigh(cov_i, cov_i + cov_other_classes)\n",
        "      V = V[:, ::-1]\n",
        "      W = np.dot(V.T, np.vstack([np.eye(data.shape[1]), np.eye(data.shape[1])]))\n",
        "      norms = np.sqrt(np.sum(W ** 2, axis=0))\n",
        "      W /= norms\n",
        "      filters.append(W)\n",
        "  return filters"
      ],
      "metadata": {
        "id": "SswazSCDNVpN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}